{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNLZ8MVUqAAEvwe0It83OOg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Phase 1: Data loading, cleaning and feature engineering"],"metadata":{"id":"2cJoWY0gBr6k"}},{"cell_type":"code","execution_count":173,"metadata":{"id":"CK2vG-LKBkqw","executionInfo":{"status":"ok","timestamp":1765657250372,"user_tz":300,"elapsed":69,"user":{"displayName":"Farhat Jahan","userId":"16702726674860757375"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import TensorDataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import roc_auc_score, accuracy_score\n","import numpy as np"]},{"cell_type":"code","source":["np.random.seed(88)"],"metadata":{"id":"5tGmUEQwTxYV","executionInfo":{"status":"ok","timestamp":1765657250377,"user_tz":300,"elapsed":1,"user":{"displayName":"Farhat Jahan","userId":"16702726674860757375"}}},"execution_count":174,"outputs":[]},{"cell_type":"code","source":["# -----------------------------------------------------------------------------\n","# STEP 1: Define column names for the dataset\n","# -----------------------------------------------------------------------------\n","\n","# These are the 14 attributes in the heart disease dataset\n","columns = [\n","    \"age\",       # Age in years\n","    \"sex\",       # Sex (1 = male; 0 = female)\n","    \"cp\",        # Chest pain type (1-4)\n","    \"trestbps\",  # Resting blood pressure (mm Hg)\n","    \"chol\",      # Serum cholesterol (mg/dl)\n","    \"fbs\",       # Fasting blood sugar > 120 mg/dl (1 = true; 0 = false)\n","    \"restecg\",   # Resting ECG results (0-2)\n","    \"thalach\",   # Maximum heart rate achieved\n","    \"exang\",     # Exercise induced angina (1 = yes; 0 = no)\n","    \"oldpeak\",   # ST depression induced by exercise\n","    \"slope\",     # Slope of peak exercise ST segment (1-3)\n","    \"ca\",        # Number of major vessels colored by fluoroscopy (0-3)\n","    \"thal\",      # Thalassemia (3 = normal; 6 = fixed defect; 7 = reversible)\n","    \"target\"     # Diagnosis (0 = no disease, 1-4 = disease severity)\n","]"],"metadata":{"id":"paUhNPd_Bx3V","executionInfo":{"status":"ok","timestamp":1765657250378,"user_tz":300,"elapsed":1,"user":{"displayName":"Farhat Jahan","userId":"16702726674860757375"}}},"execution_count":175,"outputs":[]},{"cell_type":"code","source":["# -----------------------------------------------------------------------------\n","# STEP 2: Load and combine datasets from multiple locations\n","# -----------------------------------------------------------------------------\n","# The UCI heart disease database contains data from 4 locations\n","datasets = [\n","    \"processed.cleveland.data\",\n","    \"processed.hungarian.data\",\n","    \"processed.switzerland.data\",\n","    \"processed.va.data\"\n","]\n","\n","df_list = []\n","for data_path in datasets:\n","    try:\n","        df = pd.read_csv(data_path, names=columns)\n","        # Replace '?' (missing value marker) with NaN\n","        df.replace('?', pd.NA, inplace=True)\n","        df_list.append(df)\n","        print(f\"‚úì Loaded {data_path}: {len(df)} rows\")\n","    except FileNotFoundError:\n","        print(f\"‚úó Warning: {data_path} not found, skipping...\")\n","\n","# Combine all datasets vertically\n","combined = pd.concat(df_list, ignore_index=True)\n","print(f\"\\n Total combined rows: {len(combined)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gv7S2HHYB4vs","executionInfo":{"status":"ok","timestamp":1765657250426,"user_tz":300,"elapsed":47,"user":{"displayName":"Farhat Jahan","userId":"16702726674860757375"}},"outputId":"ab6ac8c1-fb07-4ec6-abd3-8ac6f6d5477c"},"execution_count":176,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Loaded processed.cleveland.data: 303 rows\n","‚úì Loaded processed.hungarian.data: 294 rows\n","‚úì Loaded processed.switzerland.data: 123 rows\n","‚úì Loaded processed.va.data: 200 rows\n","\n"," Total combined rows: 920\n"]}]},{"cell_type":"code","source":["# -----------------------------------------------------------------------------\n","# STEP 3: Handle missing values\n","# -----------------------------------------------------------------------------\n","print(\"\\n Missing values before cleaning:\")\n","print(combined.isnull().sum())\n","\n","# Convert all columns to numeric (some may be strings due to '?')\n","for col in combined.columns:\n","    combined[col] = pd.to_numeric(combined[col], errors='coerce')\n","\n","# Fill missing values with median (robust to outliers)\n","combined.fillna(combined.median(), inplace=True)\n","\n","print(\"\\n‚úì Missing values after cleaning:\")\n","print(combined.isnull().sum())\n","\n","# Save the cleaned combined dataset\n","combined.to_csv(\"heart_disease_combined.csv\", index=False)\n","print(\"\\n Saved: heart_disease_combined.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MqCu8aC3B7I-","executionInfo":{"status":"ok","timestamp":1765657250558,"user_tz":300,"elapsed":131,"user":{"displayName":"Farhat Jahan","userId":"16702726674860757375"}},"outputId":"a53c0199-4e2e-498e-d83b-e47a66a32a67"},"execution_count":177,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," Missing values before cleaning:\n","age           0\n","sex           0\n","cp            0\n","trestbps     59\n","chol         30\n","fbs          90\n","restecg       2\n","thalach      55\n","exang        55\n","oldpeak      62\n","slope       309\n","ca          611\n","thal        486\n","target        0\n","dtype: int64\n","\n","‚úì Missing values after cleaning:\n","age         0\n","sex         0\n","cp          0\n","trestbps    0\n","chol        0\n","fbs         0\n","restecg     0\n","thalach     0\n","exang       0\n","oldpeak     0\n","slope       0\n","ca          0\n","thal        0\n","target      0\n","dtype: int64\n","\n"," Saved: heart_disease_combined.csv\n"]}]},{"cell_type":"markdown","source":["Clinical feature creation\n","\n","We will create composite features that hold stronger predictive power than the individual components."],"metadata":{"id":"euOtCEKdCAVJ"}},{"cell_type":"code","source":["df_fe = combined.copy()"],"metadata":{"id":"YvkHBFgFCUE2","executionInfo":{"status":"ok","timestamp":1765657250565,"user_tz":300,"elapsed":2,"user":{"displayName":"Farhat Jahan","userId":"16702726674860757375"}}},"execution_count":178,"outputs":[]},{"cell_type":"code","source":["## --- A. Blood Pressure Features ---\n","\n","# 1. Pulse Pressure (PP): Indicator of arterial stiffness. Higher is worse.\n","# Assuming 'trestbps' is Resting Blood Pressure\n","df_fe['pulse_pressure'] = df_fe['trestbps'] - df_fe['trestbps'].rolling(window=5).mean()\n","# A simpler version is just: df_fe['pulse_pressure'] = df_fe['trestbps'].diff()\n","\n","# 2. Mean Arterial Pressure (MAP): More representative of perfusion pressure.\n","# Using a common approximation formula: MAP ‚âà Diastolic + 1/3 * Pulse Pressure\n","# Since most datasets only have SBP ('trestbps'), we'll skip the accurate MAP calculation but note its importance.\n","\n","\n","## --- B. Cholesterol and Heart Rate Ratios ---\n","\n","# 3. Cholesterol/Thalach Ratio: Contextualizes cholesterol against cardiovascular fitness.\n","# Lower 'thalach' (max heart rate) suggests lower fitness/cardiac reserve.\n","# Higher ratio indicates high cholesterol relative to heart performance.\n","df_fe['chol_thalach_ratio'] = df_fe['chol'] / df_fe['thalach']\n","\n","# 4. Age and Cholesterol Interaction:\n","df_fe['age_chol_interaction'] = df_fe['age'] * df_fe['chol']\n","\n","\n","## --- C. Ischemic and Angina Interactions ---\n","\n","# 5. Oldpeak/Thalach Ratio: Stress-induced ST depression relative to maximum achieved heart rate.\n","# High ST depression at low heart rate is a strong negative indicator.\n","df_fe['oldpeak_thalach_ratio'] = df_fe['oldpeak'] / df_fe['thalach']\n","\n","# 6. Chest Pain Severity Score: Combine 'cp' and 'exang' (Exercise Induced Angina).\n","# Assuming 'cp' is categorical (1-4) and 'exang' is binary (0/1).\n","# We can create a weighted score where Angina (cp=4, or exang=1) contributes heavily.\n","# This assumes 'cp' is encoded such that higher values mean worse angina.\n","df_fe['angina_severity_score'] = df_fe['cp'] + (df_fe['exang'] * 2) # Multiply exang by 2 to give it extra weight\n","\n","# 7. Zero-Inflated Features (Presence Flags):\n","# Create a binary feature for important zero-valued variables.\n","# Example: Create a flag for 'oldpeak' (ST depression) if it is zero.\n","df_fe['has_zero_oldpeak'] = (df_fe['oldpeak'] == 0).astype(int)"],"metadata":{"id":"BVB8xTe_CERD","executionInfo":{"status":"ok","timestamp":1765657250586,"user_tz":300,"elapsed":20,"user":{"displayName":"Farhat Jahan","userId":"16702726674860757375"}}},"execution_count":179,"outputs":[]},{"cell_type":"markdown","source":["Categorical and numerical processing\n","\n","Proper encoding and scaling are critical before training."],"metadata":{"id":"-OGC_vn_CZIz"}},{"cell_type":"code","source":["from sklearn.preprocessing import QuantileTransformer\n","# --- A. One-Hot Encoding for Nominal Categorical Features ---\n","# Assume 'cp', 'restecg', 'slope', 'thal' are nominal/ordinal and need dummies.\n","# NOTE: Use 'drop_first=True' to avoid multicollinearity.\n","categorical_cols = ['cp', 'restecg', 'slope', 'thal']\n","df_fe = pd.get_dummies(df_fe, columns=categorical_cols, drop_first=True)\n","\n","\n","# --- B. Outlier Treatment and Scaling for Numerical Features ---\n","numerical_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak',\n","                  'pulse_pressure', 'chol_thalach_ratio', 'oldpeak_thalach_ratio', 'angina_severity_score']\n","\n","# 1. Scaling: Standard Scaling is generally good for tree-based models (XGBoost/LGBM) and critical for linear/DL models (SVM/ANN).\n","# Using robust scaling or QuantileTransformer (non-linear transformation) can be an alternative SOTA approach.\n","scaler = StandardScaler()\n","df_fe[numerical_cols] = scaler.fit_transform(df_fe[numerical_cols])\n","\n","# 2. Outlier/Skewness Treatment (Optional but Advanced):\n","quantile_transformer = QuantileTransformer(output_distribution='normal', n_quantiles=100)\n","df_fe[['chol', 'oldpeak']] = quantile_transformer.fit_transform(df_fe[['chol', 'oldpeak']])\n","\n","print(\"\\nFeature Engineering Complete. New DataFrame Shape:\", df_fe.shape)\n","print(\"New Features Created:\")\n","print(df_fe.columns[-10:])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DAWCIR1eCIam","executionInfo":{"status":"ok","timestamp":1765657250711,"user_tz":300,"elapsed":124,"user":{"displayName":"Farhat Jahan","userId":"16702726674860757375"}},"outputId":"65ab5c85-ff23-49c4-bd21-76f5a865e283"},"execution_count":180,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Feature Engineering Complete. New DataFrame Shape: (920, 25)\n","New Features Created:\n","Index(['has_zero_oldpeak', 'cp_2.0', 'cp_3.0', 'cp_4.0', 'restecg_1.0',\n","       'restecg_2.0', 'slope_2.0', 'slope_3.0', 'thal_6.0', 'thal_7.0'],\n","      dtype='object')\n"]}]},{"cell_type":"code","source":["# Before proceeding to the next model, run this on your engineered DataFrame:\n","nan_counts = df_fe.isnull().sum()\n","if nan_counts.any():\n","    print(\"WARNING: NaN values found in the following columns:\")\n","    print(nan_counts[nan_counts > 0])\n","\n","    # Simple fix: Impute the NaNs (e.g., with the mean of the column)\n","    # The NaNs likely came from the rolling mean calculation in 'pulse_pressure'\n","    df_fe.fillna(df_fe.mean(), inplace=True)\n","    print(\"\\nNaNs imputed with column mean.\")\n","else:\n","    print(\"SUCCESS: No NaN values found in the feature-engineered data.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QBCdZBWWHnkr","executionInfo":{"status":"ok","timestamp":1765657250735,"user_tz":300,"elapsed":22,"user":{"displayName":"Farhat Jahan","userId":"16702726674860757375"}},"outputId":"417f0eb6-f234-4c99-8bf9-cf9d22def139"},"execution_count":181,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING: NaN values found in the following columns:\n","pulse_pressure    4\n","dtype: int64\n","\n","NaNs imputed with column mean.\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# CRITICAL FIX 1: Convert multi-class target to binary\n","# ============================================================================\n","# The original target has values 0-4, but we need binary (0 or 1)\n","# Strategy: 0 = no disease, 1-4 = has disease\n","df_fe['target'] = (df_fe['target'] > 0).astype(int)\n","\n","print(\"Target distribution after conversion:\")\n","print(df_fe['target'].value_counts())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S978vvbJKEdv","executionInfo":{"status":"ok","timestamp":1765657250755,"user_tz":300,"elapsed":20,"user":{"displayName":"Farhat Jahan","userId":"16702726674860757375"}},"outputId":"79212249-c0ba-4a38-f101-82814967ce0c"},"execution_count":182,"outputs":[{"output_type":"stream","name":"stdout","text":["Target distribution after conversion:\n","target\n","1    509\n","0    411\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# CRITICAL FIX 2: Verify no NaN/Inf values before training\n","# ============================================================================\n","print(\"\\nChecking for NaN/Inf values...\")\n","if df_fe.isnull().any().any():\n","    print(\"WARNING: NaN values found! Imputing...\")\n","    df_fe.fillna(df_fe.mean(), inplace=True)\n","\n","# Convert DataFrame to float to handle boolean columns before checking for inf\n","if np.isinf(df_fe.astype(float).values).any():\n","    print(\"WARNING: Inf values found! Clipping...\")\n","    df_fe = df_fe.replace([np.inf, -np.inf], np.nan)\n","    df_fe.fillna(df_fe.mean(), inplace=True)\n","\n","print(\"‚úì Data validation complete\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ih3nm3ZiKOHr","executionInfo":{"status":"ok","timestamp":1765657250774,"user_tz":300,"elapsed":16,"user":{"displayName":"Farhat Jahan","userId":"16702726674860757375"}},"outputId":"1c693ccd-481d-483a-9440-73ce97de7177"},"execution_count":183,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Checking for NaN/Inf values...\n","‚úì Data validation complete\n"]}]},{"cell_type":"markdown","source":["## MLP implementation"],"metadata":{"id":"PXof3zA0a_c5"}},{"cell_type":"markdown","source":["üß† Deep Learning Approach: PyTorch MLP\n","The implementation has three main parts:\n","\n","Data Preparation: Converting Pandas/NumPy data into PyTorch Tensors and DataLoaders.\n","\n","Model Definition: Defining the structure of the Neural Network.\n","\n","Training Loop: Implementing the standard PyTorch training process.\n","\n","1. Data Preparation and Utilities\n","We need to prepare the data for PyTorch, which requires converting to NumPy, then to Tensors, and finally using DataLoader for efficient batch processing."],"metadata":{"id":"84R1ji9ZGqi-"}},{"cell_type":"code","source":["# 1. Define X and y\n","X = df_fe.drop('target', axis=1).values.astype(np.float32)\n","y = df_fe['target'].values.astype(np.float32).reshape(-1, 1) # Reshape for binary classification\n","\n","# Verify binary classification\n","unique_targets = np.unique(y)\n","print(f\"\\nUnique target values: {unique_targets}\")\n","assert len(unique_targets) == 2, f\"Target must be binary! Found {unique_targets}\"\n","\n","\n","# Split data\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42, stratify=y\n",")\n","\n","# Convert to PyTorch Tensors\n","X_train_tensor = torch.tensor(X_train)\n","y_train_tensor = torch.tensor(y_train)\n","X_test_tensor = torch.tensor(X_test)\n","y_test_tensor = torch.tensor(y_test)\n","\n","# Create DataLoader\n","train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n","BATCH_SIZE = 32\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ziIXj8_qCdOQ","executionInfo":{"status":"ok","timestamp":1765657250838,"user_tz":300,"elapsed":42,"user":{"displayName":"Farhat Jahan","userId":"16702726674860757375"}},"outputId":"c36caae2-5687-45a7-8ec3-61569c075fe5"},"execution_count":184,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Unique target values: [0. 1.]\n"]}]},{"cell_type":"markdown","source":["2. PyTorch Model Definition\n","We define a Feed-Forward Neural Network (FNN) or MLP. A common strategy for tabular data is to use funnel architecture, where the number of neurons decreases with each layer.\n","\n","Input Layer: in_features must match the number of columns in your engineered data (24).\n","\n","Activation: ReLU (Rectified Linear Unit) is the standard for hidden layers.\n","\n","Output Layer: out_features=1 for binary classification, followed by a Sigmoid activation (handled in the loss function for better numerical stability, as shown in the training step)."],"metadata":{"id":"TI5EkRRIG0Wl"}},{"cell_type":"code","source":["# ============================================================================\n","# Model Definition with Batch Normalization (IMPROVEMENT)\n","# ============================================================================\n","class HeartDiseaseMLP(nn.Module):\n","    def __init__(self, input_size):\n","        super(HeartDiseaseMLP, self).__init__()\n","\n","        # Layer sizes\n","        L1 = 128\n","        L2 = 64\n","        L3 = 32\n","\n","        # Layer 1\n","        self.fc1 = nn.Linear(input_size, L1)\n","        self.bn1 = nn.BatchNorm1d(L1)  # Added Batch Normalization\n","        self.relu1 = nn.ReLU()\n","        self.dropout1 = nn.Dropout(0.3)\n","\n","        # Layer 2\n","        self.fc2 = nn.Linear(L1, L2)\n","        self.bn2 = nn.BatchNorm1d(L2)  # Added Batch Normalization\n","        self.relu2 = nn.ReLU()\n","        self.dropout2 = nn.Dropout(0.2)  # Added dropout\n","\n","        # Layer 3\n","        self.fc3 = nn.Linear(L2, L3)\n","        self.bn3 = nn.BatchNorm1d(L3)  # Added Batch Normalization\n","        self.relu3 = nn.ReLU()\n","\n","        # Output layer\n","        self.fc4 = nn.Linear(L3, 1)\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.bn1(x)\n","        x = self.relu1(x)\n","        x = self.dropout1(x)\n","\n","        x = self.fc2(x)\n","        x = self.bn2(x)\n","        x = self.relu2(x)\n","        x = self.dropout2(x)\n","\n","        x = self.fc3(x)\n","        x = self.bn3(x)\n","        x = self.relu3(x)\n","\n","        return self.fc4(x)\n","\n","# Instantiate model\n","INPUT_SIZE = X_train.shape[1]\n","model = HeartDiseaseMLP(INPUT_SIZE)\n","print(f\"\\n‚úì Model created with {INPUT_SIZE} input features\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dKZc_-RzGu5p","executionInfo":{"status":"ok","timestamp":1765657250881,"user_tz":300,"elapsed":4,"user":{"displayName":"Farhat Jahan","userId":"16702726674860757375"}},"outputId":"0d3b23be-28b3-4e46-8140-b4ddc13eb89a"},"execution_count":185,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","‚úì Model created with 24 input features\n"]}]},{"cell_type":"markdown","source":["3. Training and Evaluation Loop\n","We use standard components for binary classification:\n","\n","Loss Function: nn.BCEWithLogitsLoss() is highly recommended for stability, as it combines the Sigmoid activation and Binary Cross-Entropy loss.\n","\n","Optimizer: Adam is the standard choice for most deep learning tasks."],"metadata":{"id":"ehZ_rZQzG6Z2"}},{"cell_type":"code","source":["# ============================================================================\n","# Training Setup\n","# ============================================================================\n","LEARNING_RATE = 1e-2  # Slightly increased for better convergence\n","NUM_EPOCHS = 150\n","EARLY_STOPPING_PATIENCE = 15\n","\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n","\n","# Learning rate scheduler\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n","    optimizer, mode='min', factor=0.5, patience=5\n",")"],"metadata":{"id":"W3x5v0xZOEMl","executionInfo":{"status":"ok","timestamp":1765657250882,"user_tz":300,"elapsed":2,"user":{"displayName":"Farhat Jahan","userId":"16702726674860757375"}}},"execution_count":186,"outputs":[]},{"cell_type":"code","source":["# ============================================================================\n","# Training Loop with Validation\n","# ============================================================================\n","print(\"\\n--- Starting PyTorch Model Training ---\\n\")\n","\n","best_loss = float('inf')\n","patience_counter = 0\n","train_losses = []\n","\n","for epoch in range(NUM_EPOCHS):\n","    model.train()\n","    epoch_loss = 0.0\n","\n","    for batch_X, batch_y in train_loader:\n","        # Forward pass\n","        outputs = model(batch_X)\n","        loss = criterion(outputs, batch_y)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","\n","    # Average loss for the epoch\n","    avg_loss = epoch_loss / len(train_loader)\n","    train_losses.append(avg_loss)\n","\n","    # Update learning rate\n","    scheduler.step(avg_loss)\n","\n","    # Early stopping check\n","    if avg_loss < best_loss:\n","        best_loss = avg_loss\n","        patience_counter = 0\n","        # Save best model\n","        best_model_state = model.state_dict().copy()\n","    else:\n","        patience_counter += 1\n","\n","    if (epoch + 1) % 10 == 0:\n","        print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Loss: {avg_loss:.4f}')\n","\n","    # Early stopping\n","    if patience_counter >= EARLY_STOPPING_PATIENCE:\n","        print(f\"\\nEarly stopping triggered at epoch {epoch+1}\")\n","        model.load_state_dict(best_model_state)\n","        break\n","\n","print(f\"\\n‚úì Training complete! Best loss: {best_loss:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j8iJII5CG3cF","executionInfo":{"status":"ok","timestamp":1765657258494,"user_tz":300,"elapsed":7609,"user":{"displayName":"Farhat Jahan","userId":"16702726674860757375"}},"outputId":"ebb627b7-c730-474d-9a71-b472290df6ac"},"execution_count":187,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Starting PyTorch Model Training ---\n","\n","Epoch [10/150], Loss: 0.5859\n","Epoch [20/150], Loss: 0.5459\n","Epoch [30/150], Loss: 0.5313\n","Epoch [40/150], Loss: 0.4954\n","Epoch [50/150], Loss: 0.4907\n","Epoch [60/150], Loss: 0.4886\n","Epoch [70/150], Loss: 0.5019\n","Epoch [80/150], Loss: 0.4899\n","Epoch [90/150], Loss: 0.4762\n","\n","Early stopping triggered at epoch 91\n","\n","‚úì Training complete! Best loss: 0.4553\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# Evaluation\n","# ============================================================================\n","model.eval()\n","with torch.no_grad():\n","    # Get predictions on test set\n","    test_logits = model(X_test_tensor)\n","    test_probabilities = torch.sigmoid(test_logits).numpy().flatten()\n","    test_predictions = (test_probabilities > 0.5).astype(int)\n","\n","    # Get predictions on train set (to check overfitting)\n","    train_logits = model(X_train_tensor)\n","    train_probabilities = torch.sigmoid(train_logits).numpy().flatten()\n","    train_predictions = (train_probabilities > 0.5).astype(int)\n","\n","    # Flatten targets\n","    y_test_flat = y_test.flatten()\n","    y_train_flat = y_train.flatten()\n","\n","    # Calculate metrics\n","    test_accuracy = accuracy_score(y_test_flat, test_predictions)\n","    test_auc = roc_auc_score(y_test_flat, test_probabilities)\n","\n","    train_accuracy = accuracy_score(y_train_flat, train_predictions)\n","    train_auc = roc_auc_score(y_train_flat, train_probabilities)"],"metadata":{"id":"BN-il5VOO3rq","executionInfo":{"status":"ok","timestamp":1765657258515,"user_tz":300,"elapsed":1,"user":{"displayName":"Farhat Jahan","userId":"16702726674860757375"}}},"execution_count":188,"outputs":[]},{"cell_type":"code","source":["# ============================================================================\n","# Results\n","# ============================================================================\n","print(\"\\n\" + \"=\"*60)\n","print(\"DEEP LEARNING MODEL RESULTS\")\n","print(\"=\"*60)\n","print(f\"Train Accuracy: {train_accuracy:.4f} | Train AUC-ROC: {train_auc:.4f}\")\n","print(f\"Test Accuracy:  {test_accuracy:.4f} | Test AUC-ROC:  {test_auc:.4f}\")\n","print(\"=\"*60)\n","\n","# Check for overfitting\n","overfit_gap = train_auc - test_auc\n","if overfit_gap > 0.1:\n","    print(f\"\\n‚ö†Ô∏è  Warning: Possible overfitting detected (gap: {overfit_gap:.4f})\")\n","else:\n","    print(f\"\\n‚úì Model generalizes well (gap: {overfit_gap:.4f})\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q_h6D2VLO-Dv","executionInfo":{"status":"ok","timestamp":1765658542480,"user_tz":300,"elapsed":45,"user":{"displayName":"Farhat Jahan","userId":"16702726674860757375"}},"outputId":"ffd5302e-ecea-47f5-8837-2b4c9953a6c5"},"execution_count":194,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","DEEP LEARNING MODEL RESULTS\n","============================================================\n","Train Accuracy: 0.7989 | Train AUC-ROC: 0.8862\n","Test Accuracy:  0.7717 | Test AUC-ROC:  0.8934\n","============================================================\n","\n","‚úì Model generalizes well (gap: -0.0072)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"zF7hn6fWYxRM"},"execution_count":null,"outputs":[]}]}